{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a Real-Time fMRI Cloud-Based Framework\n",
    "\n",
    "Authors: Grant Wallace ([gwallace@princeton.edu](mailto:gwallace@princeton.edu)) and Paula P. Brooks ([paulapbrooks@gmail.com](mailto:paulapbrooks@gmail.com))\n",
    "\n",
    "## Overview\n",
    "This notebook walks through an example using our cloud-based software framework for real-time fMRI studies, henceforth referred to as **rtcloud framework**. We have created a sample script (sample.py) in this notebook directory which builds a two-class classifier on a region of interest (ROI). This notebook will generate synthetic data for training and classification using the BrainIAK fmrisim_real_time_generator function. **Readers who are interested in running full-scale real-time fMRI studies using this framework should refer to the main [RT-Cloud Repo](https://github.com/brainiak/rt-cloud)**.\n",
    "\n",
    "We will begin wrapping the sample.py script within the rtcloud projectInterface. In a normal deployment the projectInterface (and sample.py) would then run in the cloud and the scanner images would be sent to the cloud where our sample.py script would build the classifier model and do classification. The projectInterface handles remote file communication for reading the scanner images and providing the classification results. It also has a web-based user interface for viewing and controlling the experiment and changing settings. In this notebook the different process all run on the the computer that jupyter is running on.\n",
    "\n",
    "In the steps below, we will first start the projectInterface which will watch for dicom files to process. We will then start the synthetic data generator which will generate a new dicom image every 2 seconds. And finally we will start a web browser within this notebook for controlling the experiment. Once you start the web interface you can click the 'Run' button to start the sample.py script watching for and processing images via the projectInterface. (You can also open the web interface on a different tab in your browser, http://localhost:8889.)\n",
    "\n",
    "## Annotated Bibliography\n",
    "\n",
    "1. Mennen, A.C., Turk-Browne, N.B., Wallace, G., Seok, D., Jaganjac, A., Stock, J., deBettencourt, M.T., Cohen, J.D., Norman, K.A. & Sheline, Y.I. (2020). Cloud-based fMRI neurofeedback to reduce the negative attentional bias in depression: a proof-of-concept study. *Biological Psychiatry: Cognitive Neuroscience and Neuroimaging.* [`link`](https://doi.org/10.1016/j.bpsc.2020.10.006)\n",
    "*Describes the first implementation of the  rt-cloud software framework in a closed-loop fMRI study that provided continuous neurofeedback to participants based on a multivariate pattern classifier.*\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "* [Before Running This Notebook](#setting_up)\n",
    "* [Import Necessary Modules and Declare Important Variables](#import_modules)\n",
    "* [Step 1: Start the ProjectInterface Web Server](#start_ProjectInterface)\n",
    "* [Step 2: Start the Synthetic Data Generator](#start_DataGenerator)\n",
    "* [Step 3: Open the Web Server on the localhost](#open_localhost)\n",
    "* [Summary](#summary)\n",
    "\n",
    "## Before Running This Notebook <a id='setting_up'></a>\n",
    "\n",
    "Before you are able to run this notebook, you have to complete the installation instructions found in the accompanying [instructions README](https://github.com/brainiak/brainiak-aperture/blob/master/notebooks/real-time/README_INSTRUCTIONS.md). **Also, remember that you have to complete the following steps every time before you are able to run this notebook:**\n",
    "\n",
    "1. Activate the conda environment for the rtcloud framework:\n",
    "```\n",
    "conda activate rtcloud\n",
    "```\n",
    "2. On the command line, create a global variable to the full path for the rtcloud framework repo. You must do this in order to use the functions we have created for the framework. And don't forget the forward slash \"/\" at the end.\n",
    "```\n",
    "export RTCLOUD_PATH=/PATH_TO_RTCLOUD/rt-cloud/\n",
    "```\n",
    "Double check that you did this correctly by typing the following command. \n",
    "```\n",
    "ECHO $RTCLOUD_PATH\n",
    "```\n",
    "This should print the *full* path to the rtcloud framework folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tigress/dmturner/brainiak_tests/brainiak-aperture/notebooks/real-time/rt-cloud\n"
     ]
    }
   ],
   "source": [
    "# If rt-cloud repo is present in local directory and RTCLOUD_PATH is not already set, \n",
    "# then set RTCLOUD_PATH to the local repo.\n",
    "import os\n",
    "if 'RTCLOUD_PATH' not in os.environ and os.path.exists('rt-cloud'):\n",
    "    os.environ['RTCLOUD_PATH'] = os.path.abspath('rt-cloud')\n",
    "\n",
    "!echo $RTCLOUD_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Necessary Modules and Declare Important Variables <a id='import_modules'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "#---- Import the necessary python modules\n",
    "import sys\n",
    "import threading\n",
    "import argparse\n",
    "import toml\n",
    "\n",
    "#---- Load important brainiak modules\n",
    "import brainiak.utils.fmrisim_real_time_generator as sim\n",
    "\n",
    "#---- Load important rtcloud modules\n",
    "# add the path to the rtcloud repo to PYTHONPATH to access rtCommon functions\n",
    "path_to_rtcloud = os.getenv('RTCLOUD_PATH')\n",
    "if path_to_rtcloud == None:\n",
    "    print(\"Please set RTCLOUD_PATH, see instructions\")\n",
    "    raise ValueError\n",
    "sys.path.append(path_to_rtcloud)\n",
    "\n",
    "from rtCommon.projectServer import ProjectServer\n",
    "from rtCommon.structDict import StructDict\n",
    "\n",
    "#---- Declare and append important paths \n",
    "# declare the path to this jupyter notebook\n",
    "path_to_notebook = os.getcwd()  # check and change notebook path as needed\n",
    "\n",
    "# declare the scripts that will be wrapped by the projectInterface and \n",
    "#   accessed through the webServer\n",
    "scriptToRun = os.path.join(path_to_notebook, 'sample.py')\n",
    "initScript = os.path.join(path_to_notebook, 'initialize.py')\n",
    "finalizeScript = os.path.join(path_to_notebook, 'finalize.py')\n",
    "configFile = os.path.join(path_to_notebook, 'sample-config.toml') \n",
    "\n",
    "#---- Declare the total number of TRs (timepoints) you want to generate, and how many should be training\n",
    "num_TRs = 200\n",
    "num_training = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Start the ProjectInterface Web Server <a id='start_ProjectInterface'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Settings: dataRemote:False, subjectRemote:False\n"
     ]
    }
   ],
   "source": [
    "#---- Set up the config and parameters for this rtcloud tutorial\n",
    "\n",
    "# NOTE: you can also change these parameters in the Settings tab on the web server\n",
    "config = StructDict({\n",
    "    'title' : 'rtCloud Tutorial', # study name\n",
    "    'sessionId' : '20200101T120000', # session ID on the scanner\n",
    "    'subjectName' : '001_synthetic', # subject ID on the scanner\n",
    "    'datestr' : '20200101', # session date\n",
    "    \n",
    "    'isSynthetic' : True, # are we using synthetic data?\n",
    "    'numSynthetic' : num_TRs, # total number of synthetic TRs\n",
    "    'numTrainingTRs' : num_training, # number of TRs used for training the classifier\n",
    "    'imgDir' : '/tmp/notebook-simdata', # location of synthetic TRs\n",
    "    \n",
    "    'subjectNum' : 101, # subject number\n",
    "    'subjectDay' : 1, # study day (relevant if multi-day study)\n",
    "    'sessionNum' : 1, # session number\n",
    "    'runNum' : [1], # list of scanning runs that were done during the session\n",
    "    'scanNum' : [14], # list of corresponding scan numbers for the runs\n",
    "\n",
    "    # Plotting settings\n",
    "    'plotTitle' : 'Realtime Plot', # plot title\n",
    "    'plotXLabel' : 'TR #', # plot x-axis label\n",
    "    'plotYLabel' : 'Classifier Prediction', # plot y-axis label\n",
    "    'plotXRangeLow' : num_training, # plot x-axis minimum limit\n",
    "    'plotXRangeHigh' : num_TRs, # plot x-axis maximum limit\n",
    "    'plotYRangeLow' : -1, # plot y-axis minimum limit\n",
    "    'plotYRangeHigh' : 1, # plot y-axis maximum limit\n",
    "    'plotAutoRangeX' : False, # do we want the x-axis limit to automatically fit the range?\n",
    "    'plotAutoRangeY' : True, # do we want the x-axis limit to automatically fit the range?\n",
    "\n",
    "    # important variables about the dicom files\n",
    "    'dicomNamePattern' : \"rt_{TR:03d}.dcm\", # naming pattern for the dicom files\n",
    "    'minExpectedDicomSize' : 200000, # expected size for the dicom data\n",
    "})\n",
    "\n",
    "with open(configFile, 'w') as fp:\n",
    "    toml.dump(config, fp)\n",
    "\n",
    "args = argparse.Namespace()\n",
    "args.projectName = 'sample'\n",
    "args.projectDir = path_to_notebook\n",
    "args.mainScript = scriptToRun\n",
    "args.initScript = initScript\n",
    "args.finalizeScript = finalizeScript\n",
    "args.dataRemote = False\n",
    "args.subjectRemote = False\n",
    "args.test = True\n",
    "args.config = config\n",
    "args.port = 8889\n",
    "\n",
    "\n",
    "#---- Start the project server\n",
    "def runProjectServer(args):\n",
    "    projectServer = ProjectServer(args)\n",
    "    projectServer.start()\n",
    "\n",
    "\n",
    "try:\n",
    "    project_thread = threading.Thread(name='projectServer', \n",
    "                                      target=runProjectServer,\n",
    "                                      args=(args,))\n",
    "    project_thread.setDaemon(True)\n",
    "    project_thread.start()\n",
    "except RuntimeError as err:\n",
    "    # ignore event loop already running error\n",
    "    if str(err) != 'This event loop is already running':\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "**IMPORTANT:**\n",
    "\n",
    "You can only run this cell to start the projectInterface web server only once or else you will get the following runtime error: \n",
    "```\n",
    "Web Server already running\n",
    "```\n",
    "If you want to re-start the web server, you have to first SHUT DOWN the kernel. Instructions for doing this can be found [here](https://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/execute.html#close-a-notebook-kernel-shut-down).\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Start the Synthetic Data Generator <a id='start_DataGenerator'></a>\n",
    "\n",
    "We will be using a BrainIAK function to create synthetic fMRI data. After you run the following cell, you can execute `sim_settings` in a separate cell to take a look at the different parameter settings. For instance, you will find that the synthetic data is being produced at a rate of 2 seconds per TRs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening on: http://localhost:8889\n"
     ]
    }
   ],
   "source": [
    "#---- Set up the parameters for the synthetic data generator\n",
    "\n",
    "sim_settings = sim.default_settings\n",
    "sim_settings['save_dicom'] = True\n",
    "sim_settings['save_realtime'] = True\n",
    "sim_settings['numTRs'] = num_TRs\n",
    "sim_settings['different_ROIs'] = True\n",
    "sim_settings['scale_percentage'] = 1\n",
    "\n",
    "outdir = '/tmp/notebook-simdata'\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "\n",
    "#---- Run sim.generate_data(outdir, sim_settings) as a thread\n",
    "\n",
    "syndata_thread = threading.Thread(name='syndata', \n",
    "                                  target=sim.generate_data, \n",
    "                                  args=(outdir, sim_settings))\n",
    "syndata_thread.setDaemon(True)\n",
    "syndata_thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**IMPORTANT:**\n",
    "\n",
    "You can only run this cell to generate the synthetic data in \"real-time\" once unless you delete the data that you have already created. Otherwise, all the data (which is found in the `/tmp/notebook-simdata` folder) will be automatically available when you open the web server, instead of having the File Watcher wait for incoming data one TR at a time.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Open the Web Server on the localhost <a id='open_localhost'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you will open the web-based user interface to view and control the real-time experiment, where a classification analysis will be performed. If you are interested in learning more about the details of a classifier analysis in real-time, take a look at the [real-time tutorial](https://brainiak.org/tutorials/13-real-time/) on the BrainIAK website. You will also be able to change the settings in the \"Settings\" tab.\n",
    "\n",
    "The first time you open the web server, either in the cell below or in a separate browser tab, you will be prompted to enter a username and password. In this demonstration, you will use \"test\" for both. Once you have logged in you will be on the Run tab. You can start the sample.py script running and waiting for dicom data to process by clicking the 'run' button within the webpage 'Run' tab. Then you will see the output as the script progresses within the view pane of the Run tab.\n",
    "\n",
    "If you want to re-run the sample.py script after making changes, you will most likely get the following error message: `Error: Client thread already runnning, skipping new request`. You will have to restart the kernel like in step 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"http://localhost:8889\" width=\"800\" height=\"600\"></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<iframe src=\"http://localhost:8889\" width=\"800\" height=\"600\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternate Step 3: Run the classification script from command line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of running the classification script from the web browser (as above), it can be run directly by running the scripts main function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location of the subject's dicoms: /tmp/notebook-simdata\n",
      "\n",
      "\n",
      "\n",
      "Clear any pre-existing plot for this run using 'clearRunPlot(runNum)'\n",
      "###################################################################################\n",
      "/tmp/notebook-simdata/labels.npy\n",
      "Collected training data for TR 0\n",
      "Collected training data for TR 1\n",
      "Collected training data for TR 2\n",
      "Collected training data for TR 3\n",
      "Collected training data for TR 4\n",
      "Collected training data for TR 5\n",
      "Collected training data for TR 6\n",
      "Collected training data for TR 7\n",
      "Collected training data for TR 8\n",
      "Collected training data for TR 9\n",
      "Collected training data for TR 10\n",
      "Collected training data for TR 11\n",
      "Collected training data for TR 12\n",
      "Collected training data for TR 13\n",
      "Collected training data for TR 14\n",
      "Collected training data for TR 15\n",
      "Collected training data for TR 16\n",
      "Collected training data for TR 17\n",
      "Collected training data for TR 18\n",
      "Collected training data for TR 19\n",
      "Collected training data for TR 20\n",
      "Collected training data for TR 21\n",
      "Collected training data for TR 22\n",
      "Collected training data for TR 23\n",
      "Collected training data for TR 24\n",
      "Collected training data for TR 25\n",
      "Collected training data for TR 26\n",
      "Collected training data for TR 27\n",
      "Collected training data for TR 28\n",
      "Collected training data for TR 29\n",
      "Collected training data for TR 30\n",
      "Collected training data for TR 31\n",
      "Collected training data for TR 32\n",
      "Collected training data for TR 33\n",
      "Collected training data for TR 34\n",
      "Collected training data for TR 35\n",
      "Collected training data for TR 36\n",
      "Collected training data for TR 37\n",
      "Collected training data for TR 38\n",
      "Collected training data for TR 39\n",
      "Collected training data for TR 40\n",
      "Collected training data for TR 41\n",
      "Collected training data for TR 42\n",
      "Collected training data for TR 43\n",
      "Collected training data for TR 44\n",
      "Collected training data for TR 45\n",
      "Collected training data for TR 46\n",
      "Collected training data for TR 47\n",
      "Collected training data for TR 48\n",
      "Collected training data for TR 49\n",
      "Collected training data for TR 50\n",
      "Collected training data for TR 51\n",
      "Collected training data for TR 52\n",
      "Collected training data for TR 53\n",
      "Collected training data for TR 54\n",
      "Collected training data for TR 55\n",
      "Collected training data for TR 56\n",
      "Collected training data for TR 57\n",
      "Collected training data for TR 58\n",
      "Collected training data for TR 59\n",
      "Collected training data for TR 60\n",
      "Collected training data for TR 61\n",
      "Collected training data for TR 62\n",
      "Collected training data for TR 63\n",
      "Collected training data for TR 64\n",
      "Collected training data for TR 65\n",
      "Collected training data for TR 66\n",
      "Collected training data for TR 67\n",
      "Collected training data for TR 68\n",
      "Collected training data for TR 69\n",
      "Collected training data for TR 70\n",
      "Collected training data for TR 71\n",
      "Collected training data for TR 72\n",
      "Collected training data for TR 73\n",
      "Collected training data for TR 74\n",
      "Collected training data for TR 75\n",
      "Collected training data for TR 76\n",
      "Collected training data for TR 77\n",
      "Collected training data for TR 78\n",
      "Collected training data for TR 79\n",
      "Collected training data for TR 80\n",
      "Collected training data for TR 81\n",
      "Collected training data for TR 82\n",
      "Collected training data for TR 83\n",
      "Collected training data for TR 84\n",
      "Collected training data for TR 85\n",
      "Collected training data for TR 86\n",
      "Collected training data for TR 87\n",
      "Collected training data for TR 88\n",
      "Collected training data for TR 89\n",
      "Collected training data for TR 90\n",
      "Collected training data for TR 91\n",
      "Collected training data for TR 92\n",
      "Collected training data for TR 93\n",
      "Collected training data for TR 94\n",
      "Collected training data for TR 95\n",
      "Collected training data for TR 96\n",
      "Collected training data for TR 97\n",
      "Collected training data for TR 98\n",
      "Collected training data for TR 99\n",
      "###################################################################################\n",
      "Done collecting training data! \n",
      "Start training the classifier.\n",
      "Classifier done training! Time it took: 0.00 s\n",
      "###################################################################################\n",
      "Skipping classification because it is a rest trial\n",
      "Plotting classifier prediction for TR 102: [1.]\n",
      "Plotting classifier prediction for TR 103: [1.]\n",
      "Plotting classifier prediction for TR 104: [1.]\n",
      "Plotting classifier prediction for TR 105: [1.]\n",
      "Plotting classifier prediction for TR 106: [1.]\n",
      "Skipping classification because it is a rest trial\n",
      "Skipping classification because it is a rest trial\n",
      "Skipping classification because it is a rest trial\n",
      "Plotting classifier prediction for TR 110: [1.]\n",
      "Plotting classifier prediction for TR 111: [1.]\n",
      "Plotting classifier prediction for TR 112: [1.]\n",
      "Plotting classifier prediction for TR 113: [1.]\n",
      "Plotting classifier prediction for TR 114: [1.]\n",
      "Skipping classification because it is a rest trial\n",
      "Skipping classification because it is a rest trial\n",
      "Skipping classification because it is a rest trial\n",
      "Plotting classifier prediction for TR 118: [2.]\n",
      "Plotting classifier prediction for TR 119: [1.]\n",
      "Plotting classifier prediction for TR 120: [1.]\n",
      "Plotting classifier prediction for TR 121: [1.]\n",
      "Plotting classifier prediction for TR 122: [2.]\n",
      "Skipping classification because it is a rest trial\n",
      "Skipping classification because it is a rest trial\n",
      "Skipping classification because it is a rest trial\n",
      "Plotting classifier prediction for TR 126: [2.]\n",
      "Plotting classifier prediction for TR 127: [2.]\n",
      "Plotting classifier prediction for TR 128: [2.]\n",
      "Plotting classifier prediction for TR 129: [2.]\n",
      "Plotting classifier prediction for TR 130: [1.]\n",
      "Skipping classification because it is a rest trial\n",
      "Skipping classification because it is a rest trial\n",
      "Skipping classification because it is a rest trial\n",
      "Plotting classifier prediction for TR 134: [1.]\n",
      "Plotting classifier prediction for TR 135: [1.]\n",
      "Plotting classifier prediction for TR 136: [2.]\n",
      "Plotting classifier prediction for TR 137: [1.]\n",
      "Plotting classifier prediction for TR 138: [2.]\n",
      "Skipping classification because it is a rest trial\n",
      "Skipping classification because it is a rest trial\n",
      "Skipping classification because it is a rest trial\n",
      "Plotting classifier prediction for TR 142: [1.]\n",
      "Plotting classifier prediction for TR 143: [1.]\n",
      "Plotting classifier prediction for TR 144: [1.]\n",
      "Plotting classifier prediction for TR 145: [1.]\n",
      "Plotting classifier prediction for TR 146: [1.]\n",
      "Skipping classification because it is a rest trial\n",
      "Skipping classification because it is a rest trial\n",
      "Skipping classification because it is a rest trial\n",
      "Plotting classifier prediction for TR 150: [2.]\n",
      "Plotting classifier prediction for TR 151: [2.]\n",
      "Plotting classifier prediction for TR 152: [1.]\n",
      "Plotting classifier prediction for TR 153: [2.]\n",
      "Plotting classifier prediction for TR 154: [2.]\n",
      "Skipping classification because it is a rest trial\n",
      "Skipping classification because it is a rest trial\n",
      "Skipping classification because it is a rest trial\n",
      "Plotting classifier prediction for TR 158: [1.]\n",
      "Plotting classifier prediction for TR 159: [1.]\n",
      "Plotting classifier prediction for TR 160: [2.]\n",
      "Plotting classifier prediction for TR 161: [2.]\n",
      "Plotting classifier prediction for TR 162: [2.]\n",
      "Skipping classification because it is a rest trial\n",
      "Skipping classification because it is a rest trial\n",
      "Skipping classification because it is a rest trial\n",
      "Plotting classifier prediction for TR 166: [1.]\n",
      "Plotting classifier prediction for TR 167: [1.]\n",
      "Plotting classifier prediction for TR 168: [1.]\n",
      "Plotting classifier prediction for TR 169: [1.]\n",
      "Plotting classifier prediction for TR 170: [1.]\n",
      "Skipping classification because it is a rest trial\n",
      "Skipping classification because it is a rest trial\n",
      "Skipping classification because it is a rest trial\n",
      "Plotting classifier prediction for TR 174: [1.]\n",
      "Plotting classifier prediction for TR 175: [1.]\n",
      "Plotting classifier prediction for TR 176: [1.]\n",
      "Plotting classifier prediction for TR 177: [2.]\n",
      "Plotting classifier prediction for TR 178: [2.]\n",
      "Skipping classification because it is a rest trial\n",
      "Skipping classification because it is a rest trial\n",
      "Skipping classification because it is a rest trial\n",
      "Plotting classifier prediction for TR 182: [1.]\n",
      "Plotting classifier prediction for TR 183: [2.]\n",
      "Plotting classifier prediction for TR 184: [2.]\n",
      "Plotting classifier prediction for TR 185: [2.]\n",
      "Plotting classifier prediction for TR 186: [2.]\n",
      "Skipping classification because it is a rest trial\n",
      "Skipping classification because it is a rest trial\n",
      "Skipping classification because it is a rest trial\n",
      "Plotting classifier prediction for TR 190: [1.]\n",
      "Plotting classifier prediction for TR 191: [1.]\n",
      "Plotting classifier prediction for TR 192: [1.]\n",
      "Plotting classifier prediction for TR 193: [1.]\n",
      "Plotting classifier prediction for TR 194: [2.]\n",
      "Skipping classification because it is a rest trial\n",
      "Skipping classification because it is a rest trial\n",
      "Skipping classification because it is a rest trial\n",
      "Skipping classification because it is a rest trial\n",
      "Skipping classification because it is a rest trial\n",
      "Accuracy of classifier on new data: 0.4166666666666667\n",
      "###################################################################################\n",
      "REAL-TIME EXPERIMENT COMPLETE!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the classification script directly by importing the scripts main function.\n",
    "from sample import main\n",
    "main(['-c', configFile])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary <a id='summary'></a>\n",
    "\n",
    "You have now completed running a real-time experiment using a distributed computing pipeline (managed by the projectInterface). The synthetic data was sent to the sample.py script in real-time as it was generated, and the script started by building a classifier and then performing classification.\n",
    "\n",
    "As a next step you can try modifying or using your own script in place of sample.py, and you can also try running the projectInterface on a cloud VM which eliminates the need for expensive computer hardware within the control room.\n",
    "\n",
    "We're excited to see what interesting real-time experiments you will create!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
